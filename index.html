<html>
<head>
<script>

//Based on http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/
// variables
var leftchannel = [];
var rightchannel = [];
var recorder = null;
var recording = false;
var recordingLength = 0;
var volume = null;
var audioInput = null;
var sampleRate = null;
var audioContext = null;
var context = null;
function outputElement(){return document.getElementById('audioOutput')};
var outputString;

// feature detection 
if (!navigator.getUserMedia)
    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
                  navigator.mozGetUserMedia || navigator.msGetUserMedia;

if (navigator.getUserMedia){
    navigator.getUserMedia({audio:true}, success, function(e) {
    alert('Error capturing audio.');
    console.log('getUserMedia error', e);
    });
} else alert('getUserMedia not supported in this browser.');

// when key is down
function startRecording(){
	document.getElementById("stopRecordingButton").disabled=false;
	document.getElementById("startRecordingButton").disabled=true;
      document.getElementById("speakSampleButton").disabled=true;
      document.getElementById("listenToSampleButton").disabled=true;
      document.getElementById("downloadSampleButton").disabled=true;
        recording = true;
        // reset the buffers for the new recording
        leftchannel.length = rightchannel.length = 0;
        recordingLength = 0;
        outputElement().innerHTML = 'Recording now...';
    // if S is pressed, we stop the recording and package the WAV file
    }

function stopRecording(){
	document.getElementById("stopRecordingButton").disabled=true;
	document.getElementById("startRecordingButton").disabled=false;
    document.getElementById("speakSampleButton").disabled=false;
      document.getElementById("listenToSampleButton").disabled=false;
      document.getElementById("downloadSampleButton").disabled=false;
        
        // we stop recording
        recording = false;
        
        outputElement().innerHTML = 'Building wav file...';

        // we flat the left and right channels down
        var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
        var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
        // we interleave both channels together
        var interleaved = interleave ( leftBuffer, rightBuffer );
        
        // we create our wav file
        var buffer = new ArrayBuffer(44 + interleaved.length * 2);
        var view = new DataView(buffer);
        
        // RIFF chunk descriptor
        writeUTFBytes(view, 0, 'RIFF');
        view.setUint32(4, 44 + interleaved.length * 2, true);
        writeUTFBytes(view, 8, 'WAVE');
        // FMT sub-chunk
        writeUTFBytes(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        // stereo (2 channels)
        view.setUint16(22, 2, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 4, true);
        view.setUint16(32, 4, true);
        view.setUint16(34, 16, true);
        // data sub-chunk
        writeUTFBytes(view, 36, 'data');
        view.setUint32(40, interleaved.length * 2, true);
        
        // write the PCM samples
        var lng = interleaved.length;
        var index = 44;
        var volume = 1;
        for (var i = 0; i < lng; i++){
            view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
            index += 2;
        }
        
        // our final binary blob
        var blob = new Blob ( [ view ], { type : 'audio/wav' } );
        
        // let's save it locally
        outputElement().innerHTML = 'Preparing audio sample...';
        var url = (window.URL || window.webkitURL).createObjectURL(blob);
        document.getElementById("recordedSamplePlayer").src=url;
    }

function interleave(leftChannel, rightChannel){
  var length = leftChannel.length + rightChannel.length;
  var result = new Float32Array(length);

  var inputIndex = 0;

  for (var index = 0; index < length; ){
    result[index++] = leftChannel[inputIndex];
    result[index++] = rightChannel[inputIndex];
    inputIndex++;
  }
  return result;
}

function mergeBuffers(channelBuffer, recordingLength){
  var result = new Float32Array(recordingLength);
  var offset = 0;
  var lng = channelBuffer.length;
  for (var i = 0; i < lng; i++){
    var buffer = channelBuffer[i];
    result.set(buffer, offset);
    offset += buffer.length;
  }
  return result;
}

function writeUTFBytes(view, offset, string){ 
  var lng = string.length;
  for (var i = 0; i < lng; i++){
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}

function success(e){
    // creates the audio context
    audioContext = window.AudioContext || window.webkitAudioContext;
    context = new audioContext();

	// we query the context sample rate (varies depending on platforms)
    sampleRate = context.sampleRate;

    console.log('succcess');
    
    // creates a gain node
    volume = context.createGain();

    // creates an audio node from the microphone incoming stream
    audioInput = context.createMediaStreamSource(e);

    // connect the stream to the gain node
    audioInput.connect(volume);

    /* From the spec: This value controls how frequently the audioprocess event is 
    dispatched and how many sample-frames need to be processed each call. 
    Lower values for buffer size will result in a lower (better) latency. 
    Higher values will be necessary to avoid audio breakup and glitches */
    var bufferSize = 2048;
    recorder = context.createScriptProcessor(bufferSize, 2, 2);

    recorder.onaudioprocess = function(e){
        if (!recording) return;
        var left = e.inputBuffer.getChannelData (0);
        var right = e.inputBuffer.getChannelData (1);
        // we clone the samples
        leftchannel.push (new Float32Array (left));
        rightchannel.push (new Float32Array (right));
        recordingLength += bufferSize;
        console.log('recording');
    }

    // we connect the recorder
    volume.connect (recorder);
    recorder.connect (context.destination); 
}
</script>
<script src="speakClient.js"></script>
<script>
function speechEnded()
{
	document.getElementById("stopRecordingButton").disabled=true;
	document.getElementById("startRecordingButton").disabled=false;
      document.getElementById("speakSampleButton").disabled=false;
}
function startSpeech(words)
{
	document.getElementById("startRecordingButton").disabled=true;
	speak(words);
}
function listenToSample()
{
	document.getElementById("startRecordingButton").disabled=true;
      document.getElementById("speakSampleButton").disabled=true;
      document.getElementById("recordedSamplePlayer").play();
}
function samplePlayingEnded()
{
	document.getElementById("stopRecordingButton").disabled=true;
	document.getElementById("startRecordingButton").disabled=false;
      document.getElementById("speakSampleButton").disabled=false;
}
function downloadSample()
{
        var link = window.document.createElement('a');
        link.href = document.getElementById("recordedSamplePlayer").src;
        link.download = 'output.wav';
        var click = document.createEvent("Event");
        click.initEvent("click", true, true);
        link.dispatchEvent(click);
}
</script>
</head>
<body>
<div id="audio"></div>
<script>
// This is called with the results from from FB.getLoginStatus().
  function statusChangeCallback(response) {
    console.log('statusChangeCallback');
    console.log(response);
    // The response object is returned with a status field that lets the
    // app know the current login status of the person.
    // Full docs on the response object can be found in the documentation
    // for FB.getLoginStatus().
    if (response.status === 'connected') {
      // Logged into your app and Facebook.
      testAPI();
      document.getElementById("speakSampleButton").disabled=false;
    } else if (response.status === 'not_authorized') {
      // The person is logged into Facebook, but not your app.
      document.getElementById('status').innerHTML = 'Please log ' +
        'into this app.';
    } else {
      // The person is not logged into Facebook, so we're not sure if
      // they are logged into this app or not.
      document.getElementById('status').innerHTML = 'Please log ' +
        'into Facebook.';
    }
  }

  // This function is called when someone finishes with the Login
  // Button.  See the onlogin handler attached to it in the sample
  // code below.
  function checkLoginState() {
    FB.getLoginStatus(function(response) {
      statusChangeCallback(response);
    });
  }

  // Now that we've initialized the JavaScript SDK, we call 
  // FB.getLoginStatus().  This function gets the state of the
  // person visiting this page and can return one of three states to
  // the callback you provide.  They can be:
  //
  // 1. Logged into your app ('connected')
  // 2. Logged into Facebook, but not your app ('not_authorized')
  // 3. Not logged into Facebook and can't tell if they are logged into
  //    your app or not.
  //
  // These three cases are handled in the callback function.

  
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '1632093353672522',
      xfbml      : true,
      version    : 'v2.3'
    });
    
	  FB.getLoginStatus(function(response) {
		statusChangeCallback(response);
	  });
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "//connect.facebook.net/en_US/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
   
   
  // Here we run a very simple test of the Graph API after login is
  // successful.  See statusChangeCallback() for when this call is made.
  function testAPI() {
    console.log('Welcome!  Fetching your information.... ');
    FB.api('/me', function(response) {
      console.log('Successful login for: ' + response.name);
      document.getElementById('status').innerHTML =
        'Thanks for logging in, ' + response.name + '!';
    });
  }
</script>
<ol>
<li> First, click "Allow" to allow this webpage to use your microphone.</li>
<li> Then login to facebook:  
<fb:login-button scope="public_profile,email" onlogin="checkLoginState();">
</fb:login-button>
<p>
<div id="status">
</div>
</p>
</li>
<li> I need you to record the sentence "I came for information more out of curiosity than anything else.". Please listen to a synthesized sample of the word. 
<button type="button" id="speakSampleButton" disabled="true" onclick="startSpeech('I came for information more out of curiosity than anything else.')">Click Here To Hear an Example</button></li>
<li> Now click <button type="button" disabled="true" id="startRecordingButton" onclick="startRecording()">Start Recording</button>
<p>
        <div id="audioOutput"></div></p>
</li> 
<li> When finished with your recording press <button type="button" disabled="true" id="stopRecordingButton" onclick="stopRecording()">Stop Recording</button>
    </li>
<li> Click on the <button type="button" disabled="true" id="listenToSampleButton" onclick="listenToSample()">Listen To Sample</button> to make sure you are happy with the sample</li>
<li> If you like you can <button type="button" disabled="true" id="downloadSampleButton" onclick="downloadSample()">Download the Sample</button></li>
</ol>

<audio id="recordedSamplePlayer" onEnded="samplePlayingEnded()"></audio>
</body>
</html>